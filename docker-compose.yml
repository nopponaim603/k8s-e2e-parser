version: '2'
services:

  dota2parser:
    image: nopponaim603/dota2parser:flume-v2
    ports:
      - "5600:5600"
    volumes:
      - ./JSON:/usr/src/parser/JSON
    environment:
      - JVM_OPTS=-Xms1024M -Xmx1024M
    command: java -jar -Xmx1024m /usr/src/parser/target/stats-0.1.0.jar 5600 flume 44451 1
    networks:
      # you may set custom IP addresses
      front:
        ipv4_address: 10.96.0.2

  flume:
    #image: nopponaim603/flume:kafka-1.9.0
    image: nopponaim603/flume:kafka-1.9.0-v2
    ports:
      - "44444:44444"
      - "44451:44451"
      - "44452:44452"
      - "44453:44453"
      - "44454:44454"
      - "44455:44455"
    volumes:
      - ./logs:/opt/tmp/
    environment:
      - FLUME_AGENT_NAME=docker
    networks:
      # you may set custom IP addresses
      front:
        ipv4_address: 10.96.0.3

  kafka:
    #image: wurstmeister/kafka
    #image: nopponaim603/kafka:3.2.1
    image: bitnami/kafka:latest
    ports:
      - "9092:9092"
    environment:
      ALLOW_PLAINTEXT_LISTENER: yes
      # Ref https://medium.com/@robcowart/deploying-confluent-platform-kafka-oss-using-docker-39b65fa6809b
      # JVM Heap Size
      # Kafka uses heap space very carefully and does not require setting heap sizes more than 6 GB.
      # For most use-cases I have been successful with 4GB of JVM heap.
      #KAFKA_HEAP_OPTS: '-Xms4g -Xmx4g'
      KAFKA_BROKER_ID: 0
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_CREATE_TOPICS: "sample_topic:1:1,android:1:1,acceleration:1:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # Listeners
      # As Kafka is running within the container, it is easiest to configure Kafka to listen on all IPs.
      #KAFKA_CFG_LISTENERS: PLAINTEXT://:9092
      # A Kafka broker will advertise to producers and consumers the IP address/hostname and port that it is listening on.
      # If not set, it uses the value for “listeners”. However, since Kafka is listening on all IPs,
      # the advertised listener is set explicitly to the host IP that we want to be advertised.
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.2.0.21:9092



      #KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      # Default Number of Topic Partitions
      # If the number of partitions is not specified when a topic is created, the default number of log partitions per topic is used.
      KAFKA_NUM_PARTITIONS: 2
      # Default Topic Replication Factor
      # Similar to the number of partitions, the default replication factor for automatically created topics can also be configured.
      #KAFKA_DEFAULT_REPLICATION_FACTOR: 2

      #KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - ./kafka/var/run/docker.sock:/var/run/docker.sock
    networks:
      # you may set custom IP addresses
      front:
        ipv4_address: 10.96.0.20

  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    networks:
      # you may set custom IP addresses
      front:
        ipv4_address: 10.96.0.21

  notebook:
    #image: jairamc/spark-kafka-streaming-notebook
    image: nopponaim603/jupyter-notebook:spark-kafka-3.1.2
    environment:
      SPARK_OPTS: '--master=spark://master:7077'
    command: jupyter notebook --ip=0.0.0.0 --allow-root
    ports:
      - 8888:8888
    volumes:
      - ./notebooks:/notebooks
    networks:
      # you may set custom IP addresses
      front:
        ipv4_address: 10.96.0.22

  master:
    #image: bitnami/spark
    #image: jairamc/spark-kafka-streaming
    image: nopponaim603/spark-streaming-kafka:3.1.2
    hostname: master
    environment:
      SPARK_HOME: /usr/local/spark
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /usr/local/spark/conf
      SPARK_PUBLIC_DNS: localhost
      HADOOP_HOME: /usr/local/spark
    ports:
      - 8080:8080
      - 7077:7077
      - 6066:6066
    command: /usr/local/spark/bin/spark-class org.apache.spark.deploy.master.Master -h master
    networks:
      # you may set custom IP addresses
      front:
        ipv4_address: 10.96.0.23

  slave:
    #image: jairamc/spark-kafka-streaming
    image: nopponaim603/spark-streaming-kafka:3.1.2
    hostname: worker
    depends_on:
      - master
    environment:
      SPARK_HOME: /usr/local/spark
      SPARK_CONF_DIR: /usr/local/spark/conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    ports:
      - 8081:8081
    command: /usr/local/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    networks:
      # you may set custom IP addresses
      front:
        ipv4_address: 10.96.0.24

networks:
  front:
    # use the bridge driver, but enable IPv6
    driver: bridge
    driver_opts:
      com.docker.network.enable_ipv6: "true"
    ipam:
      driver: default
      config:
        - subnet: 10.96.0.0/24
          gateway: 10.96.0.1
        - subnet: "2001:3984:3989::/64"
          gateway: "2001:3984:3989::1"